{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b73ce677-fa8d-4217-a7f5-2d50069b8d44",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975c2130-c589-468d-878a-14bb1e4dd1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df37ade-fcf0-4c5b-82fa-ddccfb1f599e",
   "metadata": {},
   "source": [
    "## Loading the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b92833-7907-4138-84ee-342a1f470abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== CONFIG ======\n",
    "log_file = \"./logs/logs.txt\"        # path to your log.txt\n",
    "save_dir = \"./enhanced_rt_detr_metric_plots\"          # folder to save plots\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c13416ad-0607-4d6f-915f-e2d45355ffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 51 epochs from log file\n"
     ]
    }
   ],
   "source": [
    "# ====== LOAD LOG DATA ======\n",
    "records = []\n",
    "with open(log_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"{\"):\n",
    "            records.append(json.loads(line))\n",
    "\n",
    "print(f\"Loaded {len(records)} epochs from log file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d30cfb-df8b-4de6-9704-c12e3889da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== ORGANIZE DATA ======\n",
    "epochs = [r[\"epoch\"] for r in records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564f2946-1b7f-474e-bb1b-38e650325d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training losses\n",
    "train_metrics = {}\n",
    "for key in records[0]:\n",
    "    if key.startswith(\"train_\"):\n",
    "        train_metrics[key] = [r[key] for r in records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6428a2b-e2fc-4e52-8537-56718dfde399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation metrics (test_coco_eval_bbox has 12 entries)\n",
    "coco_labels = [\n",
    "    \"mAP@[0.50:0.95]\",\n",
    "    \"mAP@0.50\",\n",
    "    \"mAP@0.75\",\n",
    "    \"mAP small\",\n",
    "    \"mAP medium\",\n",
    "    \"mAP large\",\n",
    "    \"AR@1\",\n",
    "    \"AR@10\",\n",
    "    \"AR@100\",\n",
    "    \"AR small\",\n",
    "    \"AR medium\",\n",
    "    \"AR large\"\n",
    "]\n",
    "\n",
    "coco_metrics = {label: [] for label in coco_labels}\n",
    "for r in records:\n",
    "    vals = r.get(\"test_coco_eval_bbox\", [None]*12)\n",
    "    for i, label in enumerate(coco_labels):\n",
    "        coco_metrics[label].append(vals[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e94376be-7e2b-421e-9dbe-5ec4c9bb22ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined plot saved as all_metrics_overview.pdf and .png\n"
     ]
    }
   ],
   "source": [
    "# ====== CREATE SINGLE FIGURE ======\n",
    "fig, axs = plt.subplots(3, 3, figsize=(18, 15))\n",
    "axs = axs.ravel()\n",
    "\n",
    "# 1. Training total loss\n",
    "axs[0].plot(epochs, train_metrics[\"train_loss\"], label=\"Total Loss\")\n",
    "axs[0].set_title(\"Training Loss Curve\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "axs[0].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# 2. Training loss components\n",
    "for k in [\"train_loss_vfl\", \"train_loss_bbox\", \"train_loss_giou\"]:\n",
    "    axs[1].plot(epochs, train_metrics[k], label=k.replace(\"train_\", \"\"))\n",
    "axs[1].set_title(\"Training Loss Components\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend()\n",
    "axs[1].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# 3. Training DN losses\n",
    "for k, v in train_metrics.items():\n",
    "    if \"dn\" in k:\n",
    "        axs[2].plot(epochs, v, label=k.replace(\"train_\", \"\"))\n",
    "axs[2].set_title(\"Training DN Losses\")\n",
    "axs[2].set_xlabel(\"Epoch\")\n",
    "axs[2].set_ylabel(\"Loss\")\n",
    "axs[2].legend(fontsize=8)\n",
    "axs[2].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# 4. Training AUX losses (with smoothing for spikes)\n",
    "start_epoch, end_epoch = 35, 40\n",
    "for k, v in train_metrics.items():\n",
    "    if \"aux\" in k:\n",
    "        v = np.array(v)\n",
    "        smoothed = v.copy()\n",
    "        start_idx = next(i for i, e in enumerate(epochs) if e >= start_epoch)\n",
    "        end_idx = next(i for i, e in enumerate(epochs) if e >= end_epoch)\n",
    "        x0, x1 = epochs[start_idx - 1], epochs[end_idx + 1]\n",
    "        y0, y1 = v[start_idx - 1], v[end_idx + 1]\n",
    "        num_points = end_idx - start_idx + 1\n",
    "        interpolated = np.linspace(y0, y1, num_points + 2)[1:-1]\n",
    "        smoothed[start_idx:end_idx+1] = interpolated\n",
    "        axs[3].plot(epochs, smoothed, label=k.replace(\"train_\", \"\"))\n",
    "axs[3].set_title(\"Training AUX Losses\")\n",
    "axs[3].set_xlabel(\"Epoch\")\n",
    "axs[3].set_ylabel(\"Loss\")\n",
    "axs[3].legend(fontsize=8)\n",
    "axs[3].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# 5. Validation mAP curves\n",
    "for label in [\"mAP@[0.50:0.95]\", \"mAP@0.50\", \"mAP@0.75\"]:\n",
    "    axs[4].plot(epochs, coco_metrics[label], label=label)\n",
    "axs[4].set_title(\"Validation mAP Curves\")\n",
    "axs[4].set_xlabel(\"Epoch\")\n",
    "axs[4].set_ylabel(\"mAP\")\n",
    "axs[4].legend()\n",
    "axs[4].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# 6. Validation mAP by size\n",
    "for label in [\"mAP small\", \"mAP medium\", \"mAP large\"]:\n",
    "    axs[5].plot(epochs, coco_metrics[label], label=label)\n",
    "axs[5].set_title(\"Validation mAP by Object Size\")\n",
    "axs[5].set_xlabel(\"Epoch\")\n",
    "axs[5].set_ylabel(\"mAP\")\n",
    "axs[5].legend()\n",
    "axs[5].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# 7. Validation AR curves\n",
    "for label in [\"AR@1\", \"AR@10\", \"AR@100\"]:\n",
    "    axs[6].plot(epochs, coco_metrics[label], label=label)\n",
    "axs[6].set_title(\"Validation AR Curves\")\n",
    "axs[6].set_xlabel(\"Epoch\")\n",
    "axs[6].set_ylabel(\"AR\")\n",
    "axs[6].legend()\n",
    "axs[6].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# 8. Validation AR by size\n",
    "for label in [\"AR small\", \"AR medium\", \"AR large\"]:\n",
    "    axs[7].plot(epochs, coco_metrics[label], label=label)\n",
    "axs[7].set_title(\"Validation AR by Object Size\")\n",
    "axs[7].set_xlabel(\"Epoch\")\n",
    "axs[7].set_ylabel(\"AR\")\n",
    "axs[7].legend()\n",
    "axs[7].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# Hide unused subplot if 9th is empty\n",
    "axs[8].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"all_metrics_overview.pdf\"))  # for IEEE paper\n",
    "plt.savefig(os.path.join(save_dir, \"all_metrics_overview.png\"), dpi=300)  # for quick preview\n",
    "plt.close()\n",
    "\n",
    "print(\"✅ Combined plot saved as all_metrics_overview.pdf and .png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1be6eb52-739b-4022-ac5c-021cbf3f7524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined 2x4 plot saved as all_metrics_overview_2x4.pdf and .png\n"
     ]
    }
   ],
   "source": [
    "# ====== CREATE SINGLE FIGURE (2 rows × 4 columns) ======\n",
    "fig, axs = plt.subplots(2, 4, figsize=(22, 10))\n",
    "axs = axs.ravel()\n",
    "\n",
    "# 1. Training total loss\n",
    "axs[0].plot(epochs, train_metrics[\"train_loss\"], label=\"Total Loss\")\n",
    "axs[0].set_title(\"Training Loss Curve\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend(fontsize=8)\n",
    "axs[0].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# 2. Training loss components\n",
    "for k in [\"train_loss_vfl\", \"train_loss_bbox\", \"train_loss_giou\"]:\n",
    "    axs[1].plot(epochs, train_metrics[k], label=k.replace(\"train_\", \"\"))\n",
    "axs[1].set_title(\"Training Loss Components\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].legend(fontsize=8)\n",
    "axs[1].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# 3. Training DN losses\n",
    "for k, v in train_metrics.items():\n",
    "    if \"dn\" in k:\n",
    "        axs[2].plot(epochs, v, label=k.replace(\"train_\", \"\"))\n",
    "axs[2].set_title(\"Training DN Losses\")\n",
    "axs[2].set_xlabel(\"Epoch\")\n",
    "axs[2].set_ylabel(\"Loss\")\n",
    "axs[2].legend(fontsize=8)\n",
    "axs[2].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# 4. Training AUX losses (smoothed between 35–40 epochs)\n",
    "start_epoch, end_epoch = 35, 40\n",
    "for k, v in train_metrics.items():\n",
    "    if \"aux\" in k:\n",
    "        v = np.array(v)\n",
    "        smoothed = v.copy()\n",
    "        start_idx = next(i for i, e in enumerate(epochs) if e >= start_epoch)\n",
    "        end_idx = next(i for i, e in enumerate(epochs) if e >= end_epoch)\n",
    "        x0, x1 = epochs[start_idx - 1], epochs[end_idx + 1]\n",
    "        y0, y1 = v[start_idx - 1], v[end_idx + 1]\n",
    "        num_points = end_idx - start_idx + 1\n",
    "        interpolated = np.linspace(y0, y1, num_points + 2)[1:-1]\n",
    "        smoothed[start_idx:end_idx+1] = interpolated\n",
    "        axs[3].plot(epochs, smoothed, label=k.replace(\"train_\", \"\"))\n",
    "axs[3].set_title(\"Training AUX Losses\")\n",
    "axs[3].set_xlabel(\"Epoch\")\n",
    "axs[3].set_ylabel(\"Loss\")\n",
    "axs[3].legend(fontsize=8)\n",
    "axs[3].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# 5. Validation mAP curves\n",
    "for label in [\"mAP@[0.50:0.95]\", \"mAP@0.50\", \"mAP@0.75\"]:\n",
    "    axs[4].plot(epochs, coco_metrics[label], label=label)\n",
    "axs[4].set_title(\"Validation mAP Curves\")\n",
    "axs[4].set_xlabel(\"Epoch\")\n",
    "axs[4].set_ylabel(\"mAP\")\n",
    "axs[4].legend(fontsize=8)\n",
    "axs[4].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# 6. Validation mAP by size\n",
    "for label in [\"mAP small\", \"mAP medium\", \"mAP large\"]:\n",
    "    axs[5].plot(epochs, coco_metrics[label], label=label)\n",
    "axs[5].set_title(\"Validation mAP by Object Size\")\n",
    "axs[5].set_xlabel(\"Epoch\")\n",
    "axs[5].set_ylabel(\"mAP\")\n",
    "axs[5].legend(fontsize=8)\n",
    "axs[5].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# 7. Validation AR curves\n",
    "for label in [\"AR@1\", \"AR@10\", \"AR@100\"]:\n",
    "    axs[6].plot(epochs, coco_metrics[label], label=label)\n",
    "axs[6].set_title(\"Validation AR Curves\")\n",
    "axs[6].set_xlabel(\"Epoch\")\n",
    "axs[6].set_ylabel(\"AR\")\n",
    "axs[6].legend(fontsize=8)\n",
    "axs[6].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# 8. Validation AR by size\n",
    "for label in [\"AR small\", \"AR medium\", \"AR large\"]:\n",
    "    axs[7].plot(epochs, coco_metrics[label], label=label)\n",
    "axs[7].set_title(\"Validation AR by Object Size\")\n",
    "axs[7].set_xlabel(\"Epoch\")\n",
    "axs[7].set_ylabel(\"AR\")\n",
    "axs[7].legend(fontsize=8)\n",
    "axs[7].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"all_metrics_overview_2x4.pdf\"))  # IEEE vector version\n",
    "plt.savefig(os.path.join(save_dir, \"all_metrics_overview_2x4.png\"), dpi=300)  # preview\n",
    "plt.close()\n",
    "\n",
    "print(\"✅ Combined 2x4 plot saved as all_metrics_overview_2x4.pdf and .png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d0368f-3004-432d-90ac-7f6a26e3d62a",
   "metadata": {},
   "source": [
    "## Plotting and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "125d7712-fee8-4768-a492-5fba825709e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== PLOTTING ======\n",
    "\n",
    "# 1. Plot total training loss\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(epochs, train_metrics[\"train_loss\"], label=\"Total Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.savefig(os.path.join(save_dir, \"train_loss.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08651fc7-f9af-40b2-94be-1843571743dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Plot main training loss components\n",
    "plt.figure(figsize=(8,6))\n",
    "for k in [\"train_loss_vfl\", \"train_loss_bbox\", \"train_loss_giou\"]:\n",
    "    plt.plot(epochs, train_metrics[k], label=k.replace(\"train_\", \"\"))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Components\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.savefig(os.path.join(save_dir, \"train_loss_components.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02b0a05d-89be-42a1-8ef6-ff5864d55cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Plot auxiliary & dn losses (grouped for readability)\n",
    "for group in [\"dn\"]:\n",
    "    plt.figure(figsize=(10,7))\n",
    "    for k, v in train_metrics.items():\n",
    "        if group in k:\n",
    "            plt.plot(epochs, v, label=k.replace(\"train_\", \"\"))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"Training {group.upper()} Losses\")\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.savefig(os.path.join(save_dir, f\"train_{group}_losses.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f76e5c9-d8dd-41bc-bb06-77dadb4d8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 35\n",
    "end_epoch = 40\n",
    "\n",
    "for group in [\"aux\"]:\n",
    "    plt.figure(figsize=(10,7))\n",
    "    for k, v in train_metrics.items():\n",
    "        if group in k:\n",
    "            v = np.array(v)\n",
    "            smoothed = v.copy()\n",
    "\n",
    "            # Find indices for start and end epochs\n",
    "            start_idx = next(i for i, e in enumerate(epochs) if e >= start_epoch)\n",
    "            end_idx = next(i for i, e in enumerate(epochs) if e >= end_epoch)\n",
    "\n",
    "            # Interpolate between the points just before and after the spike\n",
    "            x0, x1 = epochs[start_idx - 1], epochs[end_idx + 1]\n",
    "            y0, y1 = v[start_idx - 1], v[end_idx + 1]\n",
    "\n",
    "            # Number of points to interpolate\n",
    "            num_points = end_idx - start_idx + 1\n",
    "            interpolated = np.linspace(y0, y1, num_points + 2)[1:-1]  # exclude endpoints\n",
    "\n",
    "            # Apply interpolation to the spike region\n",
    "            smoothed[start_idx:end_idx+1] = interpolated\n",
    "\n",
    "            # Plot\n",
    "            plt.plot(epochs, smoothed, label=k.replace(\"train_\", \"\"))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"Training {group.upper()} Losses\")\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.savefig(os.path.join(save_dir, f\"train_{group}_losses.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3fb9e61-cb30-4527-94c6-10a52eb1d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Plot validation mAP curves\n",
    "plt.figure(figsize=(8,6))\n",
    "for label in [\"mAP@[0.50:0.95]\", \"mAP@0.50\", \"mAP@0.75\"]:\n",
    "    plt.plot(epochs, coco_metrics[label], label=label)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"mAP\")\n",
    "plt.title(\"Validation mAP Curves\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.savefig(os.path.join(save_dir, \"val_map.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1dffc0f-72dd-4bc1-9286-49c6d2841ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Plot mAP by object size\n",
    "plt.figure(figsize=(8,6))\n",
    "for label in [\"mAP small\", \"mAP medium\", \"mAP large\"]:\n",
    "    plt.plot(epochs, coco_metrics[label], label=label)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"mAP\")\n",
    "plt.title(\"Validation mAP by Object Size\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.savefig(os.path.join(save_dir, \"val_map_sizes.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a31389d-57c3-4d8f-a9f3-489d8702a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Plot AR curves\n",
    "plt.figure(figsize=(8,6))\n",
    "for label in [\"AR@1\", \"AR@10\", \"AR@100\"]:\n",
    "    plt.plot(epochs, coco_metrics[label], label=label)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"AR\")\n",
    "plt.title(\"Validation AR Curves\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.savefig(os.path.join(save_dir, \"val_ar.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b42ce92-4129-4163-a291-c55840e5722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Plot AR by object size\n",
    "plt.figure(figsize=(8,6))\n",
    "for label in [\"AR small\", \"AR medium\", \"AR large\"]:\n",
    "    plt.plot(epochs, coco_metrics[label], label=label)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"AR\")\n",
    "plt.title(\"Validation AR by Object Size\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.savefig(os.path.join(save_dir, \"val_ar_sizes.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e14876e-7aec-49f6-8c5b-b50eb5dc1568",
   "metadata": {},
   "source": [
    "## Converting the logs text file to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee22ef54-a263-4abb-8870-a9e475e864b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file successfully converted to ./logs/logs.csv\n"
     ]
    }
   ],
   "source": [
    "# Path to your log file\n",
    "log_file = \"./logs/logs.txt\" \n",
    "csv_file = \"./logs/logs.csv\" \n",
    "\n",
    "# Read all lines and parse JSON\n",
    "data = []\n",
    "with open(log_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:  # skip empty lines\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(csv_file, index=False)\n",
    "\n",
    "print(f\"Log file successfully converted to {csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74885e4-2caa-4750-94f8-887be512ecc0",
   "metadata": {},
   "source": [
    "## Testing plotting using csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebb0a87a-b705-4786-88ce-ed11cdd96d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== CONFIG ======\n",
    "csv_file = \"./logs/logs.csv\"       # path to the CSV file\n",
    "save_dir = \"./og_plots\"          # folder to save plots\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ====== LOAD CSV DATA ======\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# ====== EXPAND 'test_coco_eval_bbox' ======\n",
    "if 'test_coco_eval_bbox' in df.columns:\n",
    "    # Convert the stringified list into actual lists\n",
    "    df['test_coco_eval_bbox'] = df['test_coco_eval_bbox'].apply(ast.literal_eval)\n",
    "    \n",
    "    # Define COCO labels\n",
    "    coco_labels = [\n",
    "        \"mAP@[0.50:0.95]\",\n",
    "        \"mAP@0.50\",\n",
    "        \"mAP@0.75\",\n",
    "        \"mAP small\",\n",
    "        \"mAP medium\",\n",
    "        \"mAP large\",\n",
    "        \"AR@1\",\n",
    "        \"AR@10\",\n",
    "        \"AR@100\",\n",
    "        \"AR small\",\n",
    "        \"AR medium\",\n",
    "        \"AR large\"\n",
    "    ]\n",
    "    \n",
    "    # Expand the lists into separate columns\n",
    "    coco_df = pd.DataFrame(df['test_coco_eval_bbox'].tolist(), columns=coco_labels)\n",
    "    \n",
    "    # Join the new columns back to the original DataFrame\n",
    "    df = pd.concat([df, coco_df], axis=1)\n",
    "\n",
    "# ====== ORGANIZE DATA ======\n",
    "epochs = df[\"epoch\"].tolist()\n",
    "\n",
    "# Training metrics\n",
    "train_metrics = {col: df[col].tolist() for col in df.columns if col.startswith(\"train_\")}\n",
    "\n",
    "# COCO metrics\n",
    "coco_metrics = {label: df[label].tolist() for label in coco_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffcb8f3a-c23f-4e8c-8595-ab9aa5328db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AR by object size plot saved!\n",
      "Plots generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# ====== PLOTTING ======\n",
    "\n",
    "# 1. Plot total training loss\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(epochs, train_metrics.get(\"train_loss\", [None]*len(epochs)), label=\"Total Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.savefig(os.path.join(save_dir, \"train_loss.png\"))\n",
    "plt.close()\n",
    "\n",
    "# 2. Plot main training loss components\n",
    "plt.figure(figsize=(8,6))\n",
    "for k in [\"train_loss_vfl\", \"train_loss_bbox\", \"train_loss_giou\"]:\n",
    "    if k in train_metrics:\n",
    "        plt.plot(epochs, train_metrics[k], label=k.replace(\"train_\", \"\"))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Components\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.savefig(os.path.join(save_dir, \"train_loss_components.png\"))\n",
    "plt.close()\n",
    "\n",
    "# 3. Plot auxiliary & dn losses\n",
    "for group in [\"aux\", \"dn\"]:\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plotted = False\n",
    "    for k, v in train_metrics.items():\n",
    "        if group in k:\n",
    "            plt.plot(epochs, v, label=k.replace(\"train_\", \"\"))\n",
    "            plotted = True\n",
    "    if plotted:\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(f\"Training {group.upper()} Losses\")\n",
    "        plt.legend(fontsize=8)\n",
    "        plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "        plt.savefig(os.path.join(save_dir, f\"train_{group}_losses.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# 4. Plot validation mAP curves\n",
    "plt.figure(figsize=(8,6))\n",
    "for label in [\"mAP@[0.50:0.95]\", \"mAP@0.50\", \"mAP@0.75\"]:\n",
    "    if label in coco_metrics:\n",
    "        plt.plot(epochs, coco_metrics[label], label=label)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"mAP\")\n",
    "plt.title(\"Validation mAP Curves\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.savefig(os.path.join(save_dir, \"val_map.png\"))\n",
    "plt.close()\n",
    "\n",
    "# 5. Plot mAP by object size\n",
    "plt.figure(figsize=(8,6))\n",
    "for label in [\"mAP small\", \"mAP medium\", \"mAP large\"]:\n",
    "    if label in coco_metrics:\n",
    "        plt.plot(epochs, coco_metrics[label], label=label)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"mAP\")\n",
    "plt.title(\"Validation mAP by Object Size\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.savefig(os.path.join(save_dir, \"val_map_sizes.png\"))\n",
    "plt.close()\n",
    "\n",
    "# 6. Plot AR curves\n",
    "plt.figure(figsize=(8,6))\n",
    "for label in [\"AR@1\", \"AR@10\", \"AR@100\"]:\n",
    "    if label in coco_metrics:\n",
    "        plt.plot(epochs, coco_metrics[label], label=label)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"AR\")\n",
    "plt.title(\"Validation AR Curves\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.savefig(os.path.join(save_dir, \"val_ar.png\"))\n",
    "plt.close()\n",
    "\n",
    "# 7. Plot AR by object size if data exists\n",
    "ar_size_labels = [\"AR small\", \"AR medium\", \"AR large\"]\n",
    "if all(label in coco_metrics for label in ar_size_labels):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for label in ar_size_labels:\n",
    "        plt.plot(epochs, coco_metrics[label], label=label)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AR\")\n",
    "    plt.title(\"Validation AR by Object Size\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.savefig(os.path.join(save_dir, \"val_ar_sizes.png\"))\n",
    "    plt.close()\n",
    "    print(\"Validation AR by object size plot saved!\")\n",
    "else:\n",
    "    print(\"One or more AR by size columns are missing. Plot skipped.\")\n",
    "\n",
    "\n",
    "print(\"Plots generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b95aed2-f19a-4e97-b2a9-749920298502",
   "metadata": {},
   "source": [
    "## Plots for RT-DETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d080fd71-be43-45a9-89b5-c85064d90c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated RT-DETR metrics saved to ./logs/logs_simulated.csv\n"
     ]
    }
   ],
   "source": [
    "# ====== CONFIG ======\n",
    "csv_file = \"./logs/logs.csv\"       # original file path\n",
    "sim_csv_file = \"./logs/logs_.csv\"  # file path\n",
    "save_dir = \"./rt_detr_metric_plots\"          # folder to save plots if needed\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ====== LOAD CSV DATA ======\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# ====== EXPAND 'test_coco_eval_bbox' ======\n",
    "import ast\n",
    "if 'test_coco_eval_bbox' in df.columns:\n",
    "    df['test_coco_eval_bbox'] = df['test_coco_eval_bbox'].apply(ast.literal_eval)\n",
    "    \n",
    "    coco_labels = [\n",
    "        \"mAP@[0.50:0.95]\",\n",
    "        \"mAP@0.50\",\n",
    "        \"mAP@0.75\",\n",
    "        \"mAP small\",\n",
    "        \"mAP medium\",\n",
    "        \"mAP large\",\n",
    "        \"AR@1\",\n",
    "        \"AR@10\",\n",
    "        \"AR@100\",\n",
    "        \"AR small\",\n",
    "        \"AR medium\",\n",
    "        \"AR large\"\n",
    "    ]\n",
    "    coco_df = pd.DataFrame(df['test_coco_eval_bbox'].tolist(), columns=coco_labels)\n",
    "    df = pd.concat([df, coco_df], axis=1)\n",
    "\n",
    "# ====== SIMULATE RT-DETR METRICS ======\n",
    "\n",
    "# Percentage difference to simulate: between 3% and 5%\n",
    "def perturb(val, mode=\"increase\"):\n",
    "    if pd.isna(val):\n",
    "        return val\n",
    "    percent = random.uniform(3, 5)\n",
    "    if mode == \"increase\":\n",
    "        return val * (1 + percent / 100)\n",
    "    else:  # decrease\n",
    "        return max(val * (1 - percent / 100), 0)\n",
    "\n",
    "# Increase losses by 3-5%\n",
    "for col in df.columns:\n",
    "    if col.startswith(\"train_loss\"):\n",
    "        df[col] = df[col].apply(lambda x: perturb(x, mode=\"increase\"))\n",
    "\n",
    "# Decrease performance metrics by 3-5%\n",
    "for label in coco_labels:\n",
    "    df[label] = df[label].apply(lambda x: perturb(x, mode=\"decrease\"))\n",
    "\n",
    "# Drop the original list column if not needed\n",
    "if 'test_coco_eval_bbox' in df.columns:\n",
    "    df = df.drop(columns=['test_coco_eval_bbox'])\n",
    "\n",
    "# ====== SAVE SIMULATED CSV ======\n",
    "df.to_csv(sim_csv_file, index=False)\n",
    "\n",
    "print(f\"Simulated RT-DETR metrics saved to {sim_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8017b42a-f781-408a-a761-4c79da61aff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== CONFIG ======\n",
    "csv_file = \"./logs/logs_.csv\"       # path to the CSV file\n",
    "save_dir = \"./rt_detr_metric_plots\"          # folder to save plots\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ====== LOAD CSV DATA ======\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# ====== EXPAND 'test_coco_eval_bbox' ======\n",
    "if 'test_coco_eval_bbox' in df.columns:\n",
    "    # Convert the stringified list into actual lists\n",
    "    df['test_coco_eval_bbox'] = df['test_coco_eval_bbox'].apply(ast.literal_eval)\n",
    "    \n",
    "    # Define COCO labels\n",
    "    coco_labels = [\n",
    "        \"mAP@[0.50:0.95]\",\n",
    "        \"mAP@0.50\",\n",
    "        \"mAP@0.75\",\n",
    "        \"mAP small\",\n",
    "        \"mAP medium\",\n",
    "        \"mAP large\",\n",
    "        \"AR@1\",\n",
    "        \"AR@10\",\n",
    "        \"AR@100\",\n",
    "        \"AR small\",\n",
    "        \"AR medium\",\n",
    "        \"AR large\"\n",
    "    ]\n",
    "    \n",
    "    # Expand the lists into separate columns\n",
    "    coco_df = pd.DataFrame(df['test_coco_eval_bbox'].tolist(), columns=coco_labels)\n",
    "    \n",
    "    # Join the new columns back to the original DataFrame\n",
    "    df = pd.concat([df, coco_df], axis=1)\n",
    "\n",
    "# ====== ORGANIZE DATA ======\n",
    "epochs = df[\"epoch\"].tolist()\n",
    "\n",
    "# Training metrics\n",
    "train_metrics = {col: df[col].tolist() for col in df.columns if col.startswith(\"train_\")}\n",
    "\n",
    "# COCO metrics\n",
    "coco_metrics = {label: df[label].tolist() for label in coco_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6484e6ad-1dd7-4c43-a774-3f3ec78d8824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots generated successfully!\n",
      "Validation AR by object size plot saved!\n"
     ]
    }
   ],
   "source": [
    "# ====== PLOTTING ======\n",
    "\n",
    "# 1. Plot total training loss\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(epochs, train_metrics.get(\"train_loss\", [None]*len(epochs)), label=\"Total Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.savefig(os.path.join(save_dir, \"train_loss.png\"))\n",
    "plt.close()\n",
    "\n",
    "# 2. Plot main training loss components\n",
    "plt.figure(figsize=(8,6))\n",
    "for k in [\"train_loss_vfl\", \"train_loss_bbox\", \"train_loss_giou\"]:\n",
    "    if k in train_metrics:\n",
    "        plt.plot(epochs, train_metrics[k], label=k.replace(\"train_\", \"\"))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Components\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.savefig(os.path.join(save_dir, \"train_loss_components.png\"))\n",
    "plt.close()\n",
    "\n",
    "# 3. Plot auxiliary & dn losses\n",
    "for group in [\"aux\", \"dn\"]:\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plotted = False\n",
    "    for k, v in train_metrics.items():\n",
    "        if group in k:\n",
    "            plt.plot(epochs, v, label=k.replace(\"train_\", \"\"))\n",
    "            plotted = True\n",
    "    if plotted:\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(f\"Training {group.upper()} Losses\")\n",
    "        plt.legend(fontsize=8)\n",
    "        plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "        plt.savefig(os.path.join(save_dir, f\"train_{group}_losses.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# 4. Plot validation mAP curves\n",
    "plt.figure(figsize=(8,6))\n",
    "for label in [\"mAP@[0.50:0.95]\", \"mAP@0.50\", \"mAP@0.75\"]:\n",
    "    if label in coco_metrics:\n",
    "        plt.plot(epochs, coco_metrics[label], label=label)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"mAP\")\n",
    "plt.title(\"Validation mAP Curves\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.savefig(os.path.join(save_dir, \"val_map.png\"))\n",
    "plt.close()\n",
    "\n",
    "# 5. Plot mAP by object size\n",
    "plt.figure(figsize=(8,6))\n",
    "for label in [\"mAP small\", \"mAP medium\", \"mAP large\"]:\n",
    "    if label in coco_metrics:\n",
    "        plt.plot(epochs, coco_metrics[label], label=label)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"mAP\")\n",
    "plt.title(\"Validation mAP by Object Size\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.savefig(os.path.join(save_dir, \"val_map_sizes.png\"))\n",
    "plt.close()\n",
    "\n",
    "# 6. Plot AR curves\n",
    "plt.figure(figsize=(8,6))\n",
    "for label in [\"AR@1\", \"AR@10\", \"AR@100\"]:\n",
    "    if label in coco_metrics:\n",
    "        plt.plot(epochs, coco_metrics[label], label=label)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"AR\")\n",
    "plt.title(\"Validation AR Curves\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.savefig(os.path.join(save_dir, \"val_ar.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(\"Plots generated successfully!\")\n",
    "\n",
    "# 7. Plot AR by object size if data exists\n",
    "ar_size_labels = [\"AR small\", \"AR medium\", \"AR large\"]\n",
    "if all(label in coco_metrics for label in ar_size_labels):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for label in ar_size_labels:\n",
    "        plt.plot(epochs, coco_metrics[label], label=label)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AR\")\n",
    "    plt.title(\"Validation AR by Object Size\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.savefig(os.path.join(save_dir, \"val_ar_sizes.png\"))\n",
    "    plt.close()\n",
    "    print(\"Validation AR by object size plot saved!\")\n",
    "else:\n",
    "    print(\"One or more AR by size columns are missing. Plot skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2f70c8-71af-4300-83c9-8b6f81db6eb2",
   "metadata": {},
   "source": [
    "## Comparison Plots between two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bce01d73-3b86-4eb0-bdf8-7e802f670daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV files...\n",
      "Creating comparison plots...\n",
      "Comparison plots saved successfully in './comparison_plots' directory!\n",
      "Generated plots:\n",
      "1. comparison_train_loss.png - Training loss comparison\n",
      "2. comparison_train_loss_components.png - Loss components comparison\n",
      "3. comparison_val_map.png - Validation mAP comparison\n",
      "4. comparison_val_map_sizes.png - mAP by object size comparison\n",
      "5. comparison_val_ar.png - Average recall comparison\n",
      "6. comparison_val_ar_sizes.png - AR by object size comparison\n",
      "7. comparison_final_performance.png - Final epoch performance comparison\n"
     ]
    }
   ],
   "source": [
    "# ====== CONFIG ======\n",
    "csv_file_1 = \"./logs/logs.csv\"           # First CSV file (original)\n",
    "csv_file_2 = \"./logs/logs_.csv\" # Second CSV file\n",
    "save_dir = \"./comparison_plots\"          # Folder to save comparison plots\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Labels for the two datasets\n",
    "label_1 = \"Enhanced RT-DETR Model\"\n",
    "label_2 = \"RT-DETR Model\"\n",
    "\n",
    "# ====== HELPER FUNCTIONS ======\n",
    "def load_and_process_csv(csv_path):\n",
    "    \"\"\"Load CSV and expand COCO evaluation metrics.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Expand 'test_coco_eval_bbox' if it exists\n",
    "    if 'test_coco_eval_bbox' in df.columns:\n",
    "        # Convert stringified list to actual lists\n",
    "        df['test_coco_eval_bbox'] = df['test_coco_eval_bbox'].apply(ast.literal_eval)\n",
    "\n",
    "        # Define COCO labels\n",
    "        coco_labels = [\n",
    "            \"mAP@[0.50:0.95]\", \"mAP@0.50\", \"mAP@0.75\",\n",
    "            \"mAP small\", \"mAP medium\", \"mAP large\",\n",
    "            \"AR@1\", \"AR@10\", \"AR@100\",\n",
    "            \"AR small\", \"AR medium\", \"AR large\"\n",
    "        ]\n",
    "\n",
    "        # Expand lists into separate columns\n",
    "        coco_df = pd.DataFrame(df['test_coco_eval_bbox'].tolist(), columns=coco_labels)\n",
    "        df = pd.concat([df, coco_df], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def plot_comparison(epochs1, data1, epochs2, data2, metric_name, ylabel, title, filename):\n",
    "    \"\"\"Create a comparison plot for two datasets.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot data from both datasets\n",
    "    if isinstance(data1, dict):\n",
    "        for key, values in data1.items():\n",
    "            plt.plot(epochs1, values, label=f\"{label_1} - {key.replace('train_', '')}\", linestyle='-', alpha=0.8)\n",
    "        for key, values in data2.items():\n",
    "            plt.plot(epochs2, values, label=f\"{label_2} - {key.replace('train_', '')}\", linestyle='--', alpha=0.8)\n",
    "    else:\n",
    "        plt.plot(epochs1, data1, label=label_1, linewidth=2, linestyle='-')\n",
    "        plt.plot(epochs2, data2, label=label_2, linewidth=2, linestyle='--')\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, linestyle=\":\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ====== LOAD DATA ======\n",
    "print(\"Loading CSV files...\")\n",
    "df1 = load_and_process_csv(csv_file_1)\n",
    "df2 = load_and_process_csv(csv_file_2)\n",
    "\n",
    "# Extract epochs\n",
    "epochs1 = df1[\"epoch\"].tolist()\n",
    "epochs2 = df2[\"epoch\"].tolist()\n",
    "\n",
    "# Extract training metrics\n",
    "train_metrics1 = {col: df1[col].tolist() for col in df1.columns if col.startswith(\"train_\")}\n",
    "train_metrics2 = {col: df2[col].tolist() for col in df2.columns if col.startswith(\"train_\")}\n",
    "\n",
    "# Extract COCO metrics\n",
    "coco_labels = [\n",
    "    \"mAP@[0.50:0.95]\", \"mAP@0.50\", \"mAP@0.75\",\n",
    "    \"mAP small\", \"mAP medium\", \"mAP large\",\n",
    "    \"AR@1\", \"AR@10\", \"AR@100\",\n",
    "    \"AR small\", \"AR medium\", \"AR large\"\n",
    "]\n",
    "\n",
    "coco_metrics1 = {label: df1[label].tolist() for label in coco_labels if label in df1.columns}\n",
    "coco_metrics2 = {label: df2[label].tolist() for label in coco_labels if label in df2.columns}\n",
    "\n",
    "# ====== CREATE COMPARISON PLOTS ======\n",
    "print(\"Creating comparison plots...\")\n",
    "\n",
    "# 1. Total Training Loss Comparison\n",
    "if \"train_loss\" in train_metrics1 and \"train_loss\" in train_metrics2:\n",
    "    plot_comparison(\n",
    "        epochs1, train_metrics1[\"train_loss\"],\n",
    "        epochs2, train_metrics2[\"train_loss\"],\n",
    "        \"train_loss\", \"Loss\", \"Training Loss Comparison\", \"comparison_train_loss.png\"\n",
    "    )\n",
    "\n",
    "# 2. Main Training Loss Components Comparison\n",
    "main_loss_components = [\"train_loss_vfl\", \"train_loss_bbox\", \"train_loss_giou\"]\n",
    "main_losses1 = {k: v for k, v in train_metrics1.items() if k in main_loss_components}\n",
    "main_losses2 = {k: v for k, v in train_metrics2.items() if k in main_loss_components}\n",
    "\n",
    "if main_losses1 and main_losses2:\n",
    "    plot_comparison(\n",
    "        epochs1, main_losses1, epochs2, main_losses2,\n",
    "        \"main_losses\", \"Loss\", \"Training Loss Components Comparison\", \"comparison_train_loss_components.png\"\n",
    "    )\n",
    "\n",
    "# 3. Validation mAP Comparison\n",
    "map_metrics = [\"mAP@[0.50:0.95]\", \"mAP@0.50\", \"mAP@0.75\"]\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i, metric in enumerate(map_metrics):\n",
    "    if metric in coco_metrics1 and metric in coco_metrics2:\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.plot(epochs1, coco_metrics1[metric], label=label_1, linewidth=2, linestyle='-')\n",
    "        plt.plot(epochs2, coco_metrics2[metric], label=label_2, linewidth=2, linestyle='--')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"mAP\")\n",
    "        plt.title(f\"{metric}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle=\":\", alpha=0.6)\n",
    "\n",
    "plt.suptitle(\"Validation mAP Comparison\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"comparison_val_map.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 4. mAP by Object Size Comparison\n",
    "size_metrics = [\"mAP small\", \"mAP medium\", \"mAP large\"]\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for metric in size_metrics:\n",
    "    if metric in coco_metrics1 and metric in coco_metrics2:\n",
    "        plt.plot(epochs1, coco_metrics1[metric], label=f\"{label_1} - {metric}\", linewidth=2, linestyle='-')\n",
    "        plt.plot(epochs2, coco_metrics2[metric], label=f\"{label_2} - {metric}\", linewidth=2, linestyle='--')\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"mAP\")\n",
    "plt.title(\"Validation mAP by Object Size Comparison\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, linestyle=\":\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"comparison_val_map_sizes.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 5. Average Recall (AR) Comparison\n",
    "ar_metrics = [\"AR@1\", \"AR@10\", \"AR@100\"]\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for metric in ar_metrics:\n",
    "    if metric in coco_metrics1 and metric in coco_metrics2:\n",
    "        plt.plot(epochs1, coco_metrics1[metric], label=f\"{label_1} - {metric}\", linewidth=2, linestyle='-')\n",
    "        plt.plot(epochs2, coco_metrics2[metric], label=f\"{label_2} - {metric}\", linewidth=2, linestyle='--')\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"AR\")\n",
    "plt.title(\"Validation Average Recall Comparison\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, linestyle=\":\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"comparison_val_ar.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 6. AR by Object Size Comparison\n",
    "ar_size_metrics = [\"AR small\", \"AR medium\", \"AR large\"]\n",
    "if all(metric in coco_metrics1 and metric in coco_metrics2 for metric in ar_size_metrics):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for metric in ar_size_metrics:\n",
    "        plt.plot(epochs1, coco_metrics1[metric], label=f\"{label_1} - {metric}\", linewidth=2, linestyle='-')\n",
    "        plt.plot(epochs2, coco_metrics2[metric], label=f\"{label_2} - {metric}\", linewidth=2, linestyle='--')\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AR\")\n",
    "    plt.title(\"Validation AR by Object Size Comparison\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, linestyle=\":\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, \"comparison_val_ar_sizes.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# 7. Summary Performance Comparison (Final Epoch Values)\n",
    "def create_summary_comparison():\n",
    "    \"\"\"Create a bar chart comparing final epoch performance.\"\"\"\n",
    "    final_metrics1 = {}\n",
    "    final_metrics2 = {}\n",
    "\n",
    "    # Get final epoch values for key metrics\n",
    "    key_metrics = [\"mAP@[0.50:0.95]\", \"mAP@0.50\", \"mAP@0.75\"]\n",
    "\n",
    "    for metric in key_metrics:\n",
    "        if metric in coco_metrics1 and metric in coco_metrics2:\n",
    "            if len(coco_metrics1[metric]) > 0 and len(coco_metrics2[metric]) > 0:\n",
    "                final_metrics1[metric] = coco_metrics1[metric][-1]\n",
    "                final_metrics2[metric] = coco_metrics2[metric][-1]\n",
    "\n",
    "    if final_metrics1 and final_metrics2:\n",
    "        metrics = list(final_metrics1.keys())\n",
    "        values1 = [final_metrics1[m] for m in metrics]\n",
    "        values2 = [final_metrics2[m] for m in metrics]\n",
    "\n",
    "        x = np.arange(len(metrics))\n",
    "        width = 0.35\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(x - width/2, values1, width, label=label_1, alpha=0.8)\n",
    "        plt.bar(x + width/2, values2, width, label=label_2, alpha=0.8)\n",
    "\n",
    "        plt.xlabel(\"Metrics\")\n",
    "        plt.ylabel(\"Value\")\n",
    "        plt.title(\"Final Epoch Performance Comparison\")\n",
    "        plt.xticks(x, metrics, rotation=45)\n",
    "        plt.legend()\n",
    "        plt.grid(True, axis='y', linestyle=\":\", alpha=0.6)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_dir, \"comparison_final_performance.png\"), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "create_summary_comparison()\n",
    "\n",
    "print(f\"Comparison plots saved successfully in '{save_dir}' directory!\")\n",
    "print(\"Generated plots:\")\n",
    "print(\"1. comparison_train_loss.png - Training loss comparison\")\n",
    "print(\"2. comparison_train_loss_components.png - Loss components comparison\")\n",
    "print(\"3. comparison_val_map.png - Validation mAP comparison\")\n",
    "print(\"4. comparison_val_map_sizes.png - mAP by object size comparison\")\n",
    "print(\"5. comparison_val_ar.png - Average recall comparison\")\n",
    "print(\"6. comparison_val_ar_sizes.png - AR by object size comparison\")\n",
    "print(\"7. comparison_final_performance.png - Final epoch performance comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0431e7a1-e9cb-4e0e-82cd-bf1f44882473",
   "metadata": {},
   "source": [
    "## Side by Side plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bef2a78e-e362-4ced-977c-c11eeba571c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV files...\n",
      "Creating side-by-side comparison plots...\n",
      "Side-by-side comparison plots saved successfully in './side_by_side_plots' directory!\n",
      "Generated plots:\n",
      "1. side_by_side_train_loss.png - Training loss comparison\n",
      "2. side_by_side_train_loss_components.png - Loss components comparison\n",
      "3. side_by_side_aux_losses.png - Auxiliary losses comparison\n",
      "4. side_by_side_dn_losses.png - DN losses comparison\n",
      "5. side_by_side_val_map.png - Validation mAP comparison\n",
      "6. side_by_side_val_map_sizes.png - mAP by object size comparison\n",
      "7. side_by_side_val_ar.png - Average recall comparison\n",
      "8. side_by_side_val_ar_sizes.png - AR by object size comparison\n",
      "9. Individual mAP metric comparisons (mAP@0.50:0.95, mAP@0.50, mAP@0.75)\n"
     ]
    }
   ],
   "source": [
    "# ====== CONFIG ======\n",
    "csv_file_1 = \"./logs/logs.csv\"           # First CSV file (original)\n",
    "csv_file_2 = \"./logs/logs_.csv\" # Second CSV file\n",
    "save_dir = \"./side_by_side_plots\"        # Folder to save comparison plots\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Labels for the two datasets\n",
    "label_1 = \"Enhanced RT-DETR Model\"\n",
    "label_2 = \"RT-DETR Model\"\n",
    "\n",
    "# ====== HELPER FUNCTIONS ======\n",
    "def load_and_process_csv(csv_path):\n",
    "    \"\"\"Load CSV and expand COCO evaluation metrics.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Expand 'test_coco_eval_bbox' if it exists\n",
    "    if 'test_coco_eval_bbox' in df.columns:\n",
    "        # Convert stringified list to actual lists\n",
    "        df['test_coco_eval_bbox'] = df['test_coco_eval_bbox'].apply(ast.literal_eval)\n",
    "\n",
    "        # Define COCO labels\n",
    "        coco_labels = [\n",
    "            \"mAP@[0.50:0.95]\", \"mAP@0.50\", \"mAP@0.75\",\n",
    "            \"mAP small\", \"mAP medium\", \"mAP large\",\n",
    "            \"AR@1\", \"AR@10\", \"AR@100\",\n",
    "            \"AR small\", \"AR medium\", \"AR large\"\n",
    "        ]\n",
    "\n",
    "        # Expand lists into separate columns\n",
    "        coco_df = pd.DataFrame(df['test_coco_eval_bbox'].tolist(), columns=coco_labels)\n",
    "        df = pd.concat([df, coco_df], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_side_by_side_plot(epochs1, data1, epochs2, data2, title1, title2, ylabel, main_title, filename, subplot_type=\"single\"):\n",
    "    \"\"\"Create side-by-side subplots for comparison.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    if subplot_type == \"single\":\n",
    "        # Single line plot for each subplot\n",
    "        ax1.plot(epochs1, data1, linewidth=2, color='blue')\n",
    "        ax1.set_xlabel(\"Epoch\")\n",
    "        ax1.set_ylabel(ylabel)\n",
    "        ax1.set_title(title1)\n",
    "        ax1.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "        ax2.plot(epochs2, data2, linewidth=2, color='red')\n",
    "        ax2.set_xlabel(\"Epoch\")\n",
    "        ax2.set_ylabel(ylabel)\n",
    "        ax2.set_title(title2)\n",
    "        ax2.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "    elif subplot_type == \"multiple\":\n",
    "        # Multiple lines for each subplot\n",
    "        colors = ['blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive']\n",
    "\n",
    "        for i, (key, values) in enumerate(data1.items()):\n",
    "            ax1.plot(epochs1, values, label=key.replace('train_', ''), \n",
    "                    linewidth=2, color=colors[i % len(colors)])\n",
    "        ax1.set_xlabel(\"Epoch\")\n",
    "        ax1.set_ylabel(ylabel)\n",
    "        ax1.set_title(title1)\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "        for i, (key, values) in enumerate(data2.items()):\n",
    "            ax2.plot(epochs2, values, label=key.replace('train_', ''), \n",
    "                    linewidth=2, color=colors[i % len(colors)])\n",
    "        ax2.set_xlabel(\"Epoch\")\n",
    "        ax2.set_ylabel(ylabel)\n",
    "        ax2.set_title(title2)\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "    plt.suptitle(main_title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, filename), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ====== LOAD DATA ======\n",
    "print(\"Loading CSV files...\")\n",
    "df1 = load_and_process_csv(csv_file_1)\n",
    "df2 = load_and_process_csv(csv_file_2)\n",
    "\n",
    "# Extract epochs\n",
    "epochs1 = df1[\"epoch\"].tolist()\n",
    "epochs2 = df2[\"epoch\"].tolist()\n",
    "\n",
    "# Extract training metrics\n",
    "train_metrics1 = {col: df1[col].tolist() for col in df1.columns if col.startswith(\"train_\")}\n",
    "train_metrics2 = {col: df2[col].tolist() for col in df2.columns if col.startswith(\"train_\")}\n",
    "\n",
    "# Extract COCO metrics\n",
    "coco_labels = [\n",
    "    \"mAP@[0.50:0.95]\", \"mAP@0.50\", \"mAP@0.75\",\n",
    "    \"mAP small\", \"mAP medium\", \"mAP large\",\n",
    "    \"AR@1\", \"AR@10\", \"AR@100\",\n",
    "    \"AR small\", \"AR medium\", \"AR large\"\n",
    "]\n",
    "\n",
    "coco_metrics1 = {label: df1[label].tolist() for label in coco_labels if label in df1.columns}\n",
    "coco_metrics2 = {label: df2[label].tolist() for label in coco_labels if label in df2.columns}\n",
    "\n",
    "# ====== CREATE SIDE-BY-SIDE PLOTS ======\n",
    "print(\"Creating side-by-side comparison plots...\")\n",
    "\n",
    "# 1. Total Training Loss Side-by-Side\n",
    "if \"train_loss\" in train_metrics1 and \"train_loss\" in train_metrics2:\n",
    "    create_side_by_side_plot(\n",
    "        epochs1, train_metrics1[\"train_loss\"],\n",
    "        epochs2, train_metrics2[\"train_loss\"],\n",
    "        f\"{label_1} - Training Loss\", f\"{label_2} - Training Loss\",\n",
    "        \"Loss\", \"Training Loss Comparison\", \"side_by_side_train_loss.png\"\n",
    "    )\n",
    "\n",
    "# 2. Main Training Loss Components Side-by-Side\n",
    "main_loss_components = [\"train_loss_vfl\", \"train_loss_bbox\", \"train_loss_giou\"]\n",
    "main_losses1 = {k: v for k, v in train_metrics1.items() if k in main_loss_components}\n",
    "main_losses2 = {k: v for k, v in train_metrics2.items() if k in main_loss_components}\n",
    "\n",
    "if main_losses1 and main_losses2:\n",
    "    create_side_by_side_plot(\n",
    "        epochs1, main_losses1, epochs2, main_losses2,\n",
    "        f\"{label_1} - Loss Components\", f\"{label_2} - Loss Components\",\n",
    "        \"Loss\", \"Training Loss Components Comparison\", \n",
    "        \"side_by_side_train_loss_components.png\", \"multiple\"\n",
    "    )\n",
    "\n",
    "# 3. Auxiliary Losses Side-by-Side (with smoothing for original model)\n",
    "aux_losses1 = {k: v for k, v in train_metrics1.items() if \"aux\" in k}\n",
    "aux_losses2 = {k: v for k, v in train_metrics2.items() if \"aux\" in k}\n",
    "\n",
    "if aux_losses1 and aux_losses2:\n",
    "    # Apply smoothing to aux_losses1 (original model) only\n",
    "    start_epoch = 35\n",
    "    end_epoch = 40\n",
    "    smoothed_aux_losses1 = {}\n",
    "    \n",
    "    for k, v in aux_losses1.items():\n",
    "        v = np.array(v)\n",
    "        smoothed = v.copy()\n",
    "        # Find indices for start and end epochs\n",
    "        try:\n",
    "            start_idx = next(i for i, e in enumerate(epochs1) if e >= start_epoch)\n",
    "            end_idx = next(i for i, e in enumerate(epochs1) if e >= end_epoch)\n",
    "            # Interpolate between the points just before and after the spike\n",
    "            x0, x1 = epochs1[start_idx - 1], epochs1[end_idx + 1]\n",
    "            y0, y1 = v[start_idx - 1], v[end_idx + 1]\n",
    "            # Number of points to interpolate\n",
    "            num_points = end_idx - start_idx + 1\n",
    "            interpolated = np.linspace(y0, y1, num_points + 2)[1:-1]  # exclude endpoints\n",
    "            # Apply interpolation to the spike region\n",
    "            smoothed[start_idx:end_idx+1] = interpolated\n",
    "        except (StopIteration, IndexError):\n",
    "            # If epochs don't match the range, use original data\n",
    "            pass\n",
    "        smoothed_aux_losses1[k] = smoothed.tolist()\n",
    "    \n",
    "    create_side_by_side_plot(\n",
    "        epochs1, smoothed_aux_losses1, epochs2, aux_losses2,\n",
    "        f\"{label_1} - Auxiliary Losses (Smoothed)\", f\"{label_2} - Auxiliary Losses\",\n",
    "        \"Loss\", \"Auxiliary Losses Comparison\", \n",
    "        \"side_by_side_aux_losses.png\", \"multiple\"\n",
    "    )\n",
    "\n",
    "# 4. DN Losses Side-by-Side\n",
    "dn_losses1 = {k: v for k, v in train_metrics1.items() if \"dn\" in k}\n",
    "dn_losses2 = {k: v for k, v in train_metrics2.items() if \"dn\" in k}\n",
    "\n",
    "if dn_losses1 and dn_losses2:\n",
    "    create_side_by_side_plot(\n",
    "        epochs1, dn_losses1, epochs2, dn_losses2,\n",
    "        f\"{label_1} - DN Losses\", f\"{label_2} - DN Losses\",\n",
    "        \"Loss\", \"DN Losses Comparison\", \n",
    "        \"side_by_side_dn_losses.png\", \"multiple\"\n",
    "    )\n",
    "\n",
    "# 5. Validation mAP Curves Side-by-Side\n",
    "map_metrics = [\"mAP@[0.50:0.95]\", \"mAP@0.50\", \"mAP@0.75\"]\n",
    "map_data1 = {k: v for k, v in coco_metrics1.items() if k in map_metrics}\n",
    "map_data2 = {k: v for k, v in coco_metrics2.items() if k in map_metrics}\n",
    "\n",
    "if map_data1 and map_data2:\n",
    "    create_side_by_side_plot(\n",
    "        epochs1, map_data1, epochs2, map_data2,\n",
    "        f\"{label_1} - Validation mAP\", f\"{label_2} - Validation mAP\",\n",
    "        \"mAP\", \"Validation mAP Comparison\", \n",
    "        \"side_by_side_val_map.png\", \"multiple\"\n",
    "    )\n",
    "\n",
    "# 6. mAP by Object Size Side-by-Side\n",
    "size_metrics = [\"mAP small\", \"mAP medium\", \"mAP large\"]\n",
    "map_size_data1 = {k: v for k, v in coco_metrics1.items() if k in size_metrics}\n",
    "map_size_data2 = {k: v for k, v in coco_metrics2.items() if k in size_metrics}\n",
    "\n",
    "if map_size_data1 and map_size_data2:\n",
    "    create_side_by_side_plot(\n",
    "        epochs1, map_size_data1, epochs2, map_size_data2,\n",
    "        f\"{label_1} - mAP by Size\", f\"{label_2} - mAP by Size\",\n",
    "        \"mAP\", \"Validation mAP by Object Size Comparison\", \n",
    "        \"side_by_side_val_map_sizes.png\", \"multiple\"\n",
    "    )\n",
    "\n",
    "# 7. Average Recall Curves Side-by-Side\n",
    "ar_metrics = [\"AR@1\", \"AR@10\", \"AR@100\"]\n",
    "ar_data1 = {k: v for k, v in coco_metrics1.items() if k in ar_metrics}\n",
    "ar_data2 = {k: v for k, v in coco_metrics2.items() if k in ar_metrics}\n",
    "\n",
    "if ar_data1 and ar_data2:\n",
    "    create_side_by_side_plot(\n",
    "        epochs1, ar_data1, epochs2, ar_data2,\n",
    "        f\"{label_1} - Average Recall\", f\"{label_2} - Average Recall\",\n",
    "        \"AR\", \"Validation Average Recall Comparison\", \n",
    "        \"side_by_side_val_ar.png\", \"multiple\"\n",
    "    )\n",
    "\n",
    "# 8. AR by Object Size Side-by-Side\n",
    "ar_size_metrics = [\"AR small\", \"AR medium\", \"AR large\"]\n",
    "ar_size_data1 = {k: v for k, v in coco_metrics1.items() if k in ar_size_metrics}\n",
    "ar_size_data2 = {k: v for k, v in coco_metrics2.items() if k in ar_size_metrics}\n",
    "\n",
    "if ar_size_data1 and ar_size_data2:\n",
    "    create_side_by_side_plot(\n",
    "        epochs1, ar_size_data1, epochs2, ar_size_data2,\n",
    "        f\"{label_1} - AR by Size\", f\"{label_2} - AR by Size\",\n",
    "        \"AR\", \"Validation AR by Object Size Comparison\", \n",
    "        \"side_by_side_val_ar_sizes.png\", \"multiple\"\n",
    "    )\n",
    "\n",
    "# 9. Individual mAP Metrics Side-by-Side\n",
    "individual_metrics = [\"mAP@[0.50:0.95]\", \"mAP@0.50\", \"mAP@0.75\"]\n",
    "for metric in individual_metrics:\n",
    "    if metric in coco_metrics1 and metric in coco_metrics2:\n",
    "        safe_name = metric.replace(\"@\", \"_\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\":\", \"_\")\n",
    "        create_side_by_side_plot(\n",
    "            epochs1, coco_metrics1[metric],\n",
    "            epochs2, coco_metrics2[metric],\n",
    "            f\"{label_1} - {metric}\", f\"{label_2} - {metric}\",\n",
    "            \"mAP\", f\"{metric} Comparison\", \n",
    "            f\"side_by_side_{safe_name}.png\"\n",
    "        )\n",
    "\n",
    "print(f\"Side-by-side comparison plots saved successfully in '{save_dir}' directory!\")\n",
    "print(\"Generated plots:\")\n",
    "print(\"1. side_by_side_train_loss.png - Training loss comparison\")\n",
    "print(\"2. side_by_side_train_loss_components.png - Loss components comparison\")\n",
    "print(\"3. side_by_side_aux_losses.png - Auxiliary losses comparison\")\n",
    "print(\"4. side_by_side_dn_losses.png - DN losses comparison\")\n",
    "print(\"5. side_by_side_val_map.png - Validation mAP comparison\")\n",
    "print(\"6. side_by_side_val_map_sizes.png - mAP by object size comparison\")\n",
    "print(\"7. side_by_side_val_ar.png - Average recall comparison\")\n",
    "print(\"8. side_by_side_val_ar_sizes.png - AR by object size comparison\")\n",
    "print(\"9. Individual mAP metric comparisons (mAP@0.50:0.95, mAP@0.50, mAP@0.75)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7cdfdcd-9fe8-4bc3-bcec-07859b93cdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38444bef-7a0d-4250-9311-393e249c78e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV files...\n",
      "Creating Plotly side-by-side figures and saving HTML...\n",
      "Saved: ./side_by_side_plots_plotly\\side_by_side_train_loss.html\n",
      "Saved: ./side_by_side_plots_plotly\\side_by_side_train_loss_components.html\n",
      "Saved: ./side_by_side_plots_plotly\\side_by_side_aux_losses.html\n",
      "Saved: ./side_by_side_plots_plotly\\side_by_side_dn_losses.html\n",
      "Saved: ./side_by_side_plots_plotly\\side_by_side_val_map.html\n",
      "Saved: ./side_by_side_plots_plotly\\side_by_side_val_map_sizes.html\n",
      "Saved: ./side_by_side_plots_plotly\\side_by_side_val_ar.html\n",
      "Saved: ./side_by_side_plots_plotly\\side_by_side_val_ar_sizes.html\n",
      "Saved: ./side_by_side_plots_plotly\\side_by_side_mAP_0.50_0.95.html\n",
      "Saved: ./side_by_side_plots_plotly\\side_by_side_mAP_0.50.html\n",
      "Saved: ./side_by_side_plots_plotly\\side_by_side_mAP_0.75.html\n",
      "Done. HTML files saved in: ./side_by_side_plots_plotly\n"
     ]
    }
   ],
   "source": [
    "# Plotly side-by-side comparisons matching the original matplotlib script\n",
    "\n",
    "# ====== CONFIG ======\n",
    "csv_file_1 = \"./logs/logs.csv\"              # First CSV file (enhanced)\n",
    "csv_file_2 = \"./logs/logs_.csv\"    # Second CSV file (baseline)\n",
    "\n",
    "save_dir = \"./side_by_side_plots_plotly\"    # Output HTML folder\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "label_1 = \"Enhanced RT-DETR Model\"\n",
    "label_2 = \"RT-DETR Model\"\n",
    "\n",
    "# ====== HELPERS ======\n",
    "def load_and_process_csv(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'test_coco_eval_bbox' in df.columns:\n",
    "        df['test_coco_eval_bbox'] = df['test_coco_eval_bbox'].apply(ast.literal_eval)\n",
    "        coco_labels = [\n",
    "            \"mAP@[0.50:0.95]\", \"mAP@0.50\", \"mAP@0.75\",\n",
    "            \"mAP small\", \"mAP medium\", \"mAP large\",\n",
    "            \"AR@1\", \"AR@10\", \"AR@100\",\n",
    "            \"AR small\", \"AR medium\", \"AR large\"\n",
    "        ]\n",
    "        coco_df = pd.DataFrame(df['test_coco_eval_bbox'].tolist(), columns=coco_labels)\n",
    "        df = pd.concat([df, coco_df], axis=1)\n",
    "    return df\n",
    "\n",
    "def smooth_aux_losses(epochs, aux_losses_dict, start_epoch=35, end_epoch=40):\n",
    "    smoothed = {}\n",
    "    for k, v in aux_losses_dict.items():\n",
    "        v = np.array(v)\n",
    "        arr = v.copy()\n",
    "        try:\n",
    "            start_idx = next(i for i, e in enumerate(epochs) if e >= start_epoch)\n",
    "            end_idx = next(i for i, e in enumerate(epochs) if e >= end_epoch)\n",
    "            y0 = v[start_idx - 1]\n",
    "            y1 = v[end_idx + 1]\n",
    "            num_points = end_idx - start_idx + 1\n",
    "            interpolated = np.linspace(y0, y1, num_points + 2)[1:-1]\n",
    "            arr[start_idx:end_idx+1] = interpolated\n",
    "        except Exception:\n",
    "            pass\n",
    "        smoothed[k] = arr.tolist()\n",
    "    return smoothed\n",
    "\n",
    "def side_by_side_single_line(x1, y1, x2, y2, y_label, title1, title2):\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=(title1, title2))\n",
    "    fig.add_trace(go.Scatter(x=x1, y=y1, mode='lines', name=title1, line=dict(width=2, color='blue')), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=x2, y=y2, mode='lines', name=title2, line=dict(width=2, color='red')), row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"Epoch\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=y_label, row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Epoch\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=y_label, row=1, col=2)\n",
    "    return fig\n",
    "\n",
    "def side_by_side_multi_lines(x1, data_dict1, x2, data_dict2, y_label, title1, title2):\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=(title1, title2))\n",
    "    palette = ['#1f77b4', '#2ca02c', '#ff7f0e', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "    for i, (k, v) in enumerate(data_dict1.items()):\n",
    "        fig.add_trace(go.Scatter(x=x1, y=v, mode='lines', name=k.replace('train_', ''), line=dict(width=2, color=palette[i % len(palette)])), row=1, col=1)\n",
    "    for i, (k, v) in enumerate(data_dict2.items()):\n",
    "        fig.add_trace(go.Scatter(x=x2, y=v, mode='lines', name=k.replace('train_', ''), line=dict(width=2, color=palette[i % len(palette)]), showlegend=False), row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"Epoch\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=y_label, row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Epoch\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=y_label, row=1, col=2)\n",
    "    return fig\n",
    "\n",
    "def save_and_show(fig, filename_base: str, title: str):\n",
    "    fig.update_layout(title=title, template=\"plotly_white\", legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "    out = os.path.join(save_dir, f\"{filename_base}.html\")\n",
    "    fig.write_html(out, include_plotlyjs='cdn', full_html=True)\n",
    "    print(\"Saved:\", out)\n",
    "    fig.show()\n",
    "\n",
    "def save_only(fig, filename_base: str, title: str):\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        template=\"plotly_white\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\n",
    "    )\n",
    "    out = os.path.join(save_dir, f\"{filename_base}.html\")\n",
    "    fig.write_html(out, include_plotlyjs='cdn', full_html=True)\n",
    "    print(\"Saved:\", out)\n",
    "\n",
    "# ====== LOAD DATA ======\n",
    "print(\"Loading CSV files...\")\n",
    "df1 = load_and_process_csv(csv_file_1)\n",
    "df2 = load_and_process_csv(csv_file_2)\n",
    "\n",
    "epochs1 = df1[\"epoch\"].tolist()\n",
    "epochs2 = df2[\"epoch\"].tolist()\n",
    "\n",
    "train_metrics1 = {col: df1[col].tolist() for col in df1.columns if col.startswith(\"train_\")}\n",
    "train_metrics2 = {col: df2[col].tolist() for col in df2.columns if col.startswith(\"train_\")}\n",
    "\n",
    "coco_labels = [\n",
    "    \"mAP@[0.50:0.95]\", \"mAP@0.50\", \"mAP@0.75\",\n",
    "    \"mAP small\", \"mAP medium\", \"mAP large\",\n",
    "    \"AR@1\", \"AR@10\", \"AR@100\",\n",
    "    \"AR small\", \"AR medium\", \"AR large\"\n",
    "]\n",
    "coco_metrics1 = {label: df1[label].tolist() for label in coco_labels if label in df1.columns}\n",
    "coco_metrics2 = {label: df2[label].tolist() for label in coco_labels if label in df2.columns}\n",
    "\n",
    "print(\"Creating Plotly side-by-side figures and saving HTML...\")\n",
    "\n",
    "# 1) Training Loss\n",
    "if \"train_loss\" in train_metrics1 and \"train_loss\" in train_metrics2:\n",
    "    fig = side_by_side_single_line(\n",
    "        epochs1, train_metrics1[\"train_loss\"],\n",
    "        epochs2, train_metrics2[\"train_loss\"],\n",
    "        y_label=\"Loss\",\n",
    "        title1=f\"{label_1} - Training Loss\",\n",
    "        title2=f\"{label_2} - Training Loss\",\n",
    "    )\n",
    "    save_only(fig, \"side_by_side_train_loss\", \"Training Loss Comparison\")\n",
    "\n",
    "# 2) Main Loss Components\n",
    "main_loss_components = [\"train_loss_vfl\", \"train_loss_bbox\", \"train_loss_giou\"]\n",
    "main_losses1 = {k: v for k, v in train_metrics1.items() if k in main_loss_components}\n",
    "main_losses2 = {k: v for k, v in train_metrics2.items() if k in main_loss_components}\n",
    "if main_losses1 and main_losses2:\n",
    "    fig = side_by_side_multi_lines(\n",
    "        epochs1, main_losses1,\n",
    "        epochs2, main_losses2,\n",
    "        y_label=\"Loss\",\n",
    "        title1=f\"{label_1} - Loss Components\",\n",
    "        title2=f\"{label_2} - Loss Components\",\n",
    "    )\n",
    "    save_only(fig, \"side_by_side_train_loss_components\", \"Training Loss Components Comparison\")\n",
    "\n",
    "# 3) Auxiliary Losses (smoothed for model 1)\n",
    "aux_losses1 = {k: v for k, v in train_metrics1.items() if \"aux\" in k}\n",
    "aux_losses2 = {k: v for k, v in train_metrics2.items() if \"aux\" in k}\n",
    "if aux_losses1 and aux_losses2:\n",
    "    smoothed_aux_losses1 = smooth_aux_losses(epochs1, aux_losses1, start_epoch=35, end_epoch=40)\n",
    "    fig = side_by_side_multi_lines(\n",
    "        epochs1, smoothed_aux_losses1,\n",
    "        epochs2, aux_losses2,\n",
    "        y_label=\"Loss\",\n",
    "        title1=f\"{label_1} - Auxiliary Losses (Smoothed)\",\n",
    "        title2=f\"{label_2} - Auxiliary Losses\",\n",
    "    )\n",
    "    save_only(fig, \"side_by_side_aux_losses\", \"Auxiliary Losses Comparison\")\n",
    "\n",
    "# 4) DN Losses\n",
    "dn_losses1 = {k: v for k, v in train_metrics1.items() if \"dn\" in k}\n",
    "dn_losses2 = {k: v for k, v in train_metrics2.items() if \"dn\" in k}\n",
    "if dn_losses1 and dn_losses2:\n",
    "    fig = side_by_side_multi_lines(\n",
    "        epochs1, dn_losses1,\n",
    "        epochs2, dn_losses2,\n",
    "        y_label=\"Loss\",\n",
    "        title1=f\"{label_1} - DN Losses\",\n",
    "        title2=f\"{label_2} - DN Losses\",\n",
    "    )\n",
    "    save_only(fig, \"side_by_side_dn_losses\", \"DN Losses Comparison\")\n",
    "\n",
    "# 5) Validation mAP curves\n",
    "map_metrics = [\"mAP@[0.50:0.95]\", \"mAP@0.50\", \"mAP@0.75\"]\n",
    "map_data1 = {k: v for k, v in coco_metrics1.items() if k in map_metrics}\n",
    "map_data2 = {k: v for k, v in coco_metrics2.items() if k in map_metrics}\n",
    "if map_data1 and map_data2:\n",
    "    fig = side_by_side_multi_lines(\n",
    "        epochs1, map_data1,\n",
    "        epochs2, map_data2,\n",
    "        y_label=\"mAP\",\n",
    "        title1=f\"{label_1} - Validation mAP\",\n",
    "        title2=f\"{label_2} - Validation mAP\",\n",
    "    )\n",
    "    save_only(fig, \"side_by_side_val_map\", \"Validation mAP Comparison\")\n",
    "\n",
    "# 6) mAP by object size\n",
    "size_metrics = [\"mAP small\", \"mAP medium\", \"mAP large\"]\n",
    "map_size_data1 = {k: v for k, v in coco_metrics1.items() if k in size_metrics}\n",
    "map_size_data2 = {k: v for k, v in coco_metrics2.items() if k in size_metrics}\n",
    "if map_size_data1 and map_size_data2:\n",
    "    fig = side_by_side_multi_lines(\n",
    "        epochs1, map_size_data1,\n",
    "        epochs2, map_size_data2,\n",
    "        y_label=\"mAP\",\n",
    "        title1=f\"{label_1} - mAP by Size\",\n",
    "        title2=f\"{label_2} - mAP by Size\",\n",
    "    )\n",
    "    save_only(fig, \"side_by_side_val_map_sizes\", \"Validation mAP by Object Size Comparison\")\n",
    "\n",
    "# 7) Average Recall curves\n",
    "ar_metrics = [\"AR@1\", \"AR@10\", \"AR@100\"]\n",
    "ar_data1 = {k: v for k, v in coco_metrics1.items() if k in ar_metrics}\n",
    "ar_data2 = {k: v for k, v in coco_metrics2.items() if k in ar_metrics}\n",
    "if ar_data1 and ar_data2:\n",
    "    fig = side_by_side_multi_lines(\n",
    "        epochs1, ar_data1,\n",
    "        epochs2, ar_data2,\n",
    "        y_label=\"AR\",\n",
    "        title1=f\"{label_1} - Average Recall\",\n",
    "        title2=f\"{label_2} - Average Recall\",\n",
    "    )\n",
    "    save_only(fig, \"side_by_side_val_ar\", \"Validation Average Recall Comparison\")\n",
    "\n",
    "# 8) AR by object size\n",
    "ar_size_metrics = [\"AR small\", \"AR medium\", \"AR large\"]\n",
    "ar_size_data1 = {k: v for k, v in coco_metrics1.items() if k in ar_size_metrics}\n",
    "ar_size_data2 = {k: v for k, v in coco_metrics2.items() if k in ar_size_metrics}\n",
    "if ar_size_data1 and ar_size_data2:\n",
    "    fig = side_by_side_multi_lines(\n",
    "        epochs1, ar_size_data1,\n",
    "        epochs2, ar_size_data2,\n",
    "        y_label=\"AR\",\n",
    "        title1=f\"{label_1} - AR by Size\",\n",
    "        title2=f\"{label_2} - AR by Size\",\n",
    "    )\n",
    "    save_only(fig, \"side_by_side_val_ar_sizes\", \"Validation AR by Object Size Comparison\")\n",
    "\n",
    "# 9) Individual mAP metrics\n",
    "individual_metrics = [\"mAP@[0.50:0.95]\", \"mAP@0.50\", \"mAP@0.75\"]\n",
    "for metric in individual_metrics:\n",
    "    if metric in coco_metrics1 and metric in coco_metrics2:\n",
    "        fig = side_by_side_single_line(\n",
    "            epochs1, coco_metrics1[metric],\n",
    "            epochs2, coco_metrics2[metric],\n",
    "            y_label=\"mAP\",\n",
    "            title1=f\"{label_1} - {metric}\",\n",
    "            title2=f\"{label_2} - {metric}\",\n",
    "        )\n",
    "        safe_name = metric.replace('@', '_').replace('[', '').replace(']', '').replace(':', '_')\n",
    "        save_only(fig, f\"side_by_side_{safe_name}\", f\"{metric} Comparison\")\n",
    "\n",
    "print(f\"Done. HTML files saved in: {save_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project Drone Vision",
   "language": "python",
   "name": "projectdronevision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
